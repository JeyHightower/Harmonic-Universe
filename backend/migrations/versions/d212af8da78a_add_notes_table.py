"""add notes table

Revision ID: d212af8da78a
Revises: 5da119559737
Create Date: 2025-05-12 19:04:54.507786

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.engine.reflection import Inspector
import logging

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# revision identifiers, used by Alembic.
revision = 'd212af8da78a'
down_revision = '5da119559737'
branch_labels = None
depends_on = None


def upgrade():
    # Get connection to database
    conn = op.get_bind()

    # Try different methods to get inspector
    try:
        # Try direct connection first
        inspector = Inspector.from_engine(conn.engine)
        tables = inspector.get_table_names()
        logger.info(f"Tables found with method 1: {tables}")
    except Exception as e:
        logger.info(f"Method 1 failed with: {str(e)}")
        try:
            # Try with conn.engine if direct connection fails
            inspector = Inspector.from_engine(conn.engine)
            tables = inspector.get_table_names()
            logger.info(f"Tables found with method 2: {tables}")
        except Exception as e:
            logger.info(f"Method 2 failed with: {str(e)}")
            # Fallback to raw SQL
            try:
                result = conn.execute(sa.text("SELECT table_name FROM information_schema.tables WHERE table_schema = 'public'"))
                tables = [row[0] for row in result]
                logger.info(f"Tables found with raw SQL: {tables}")
            except Exception as e:
                logger.info(f"Raw SQL method failed with: {str(e)}")
                tables = []

    # ### commands auto generated by Alembic - please adjust! ###
    logger.info(f"Checking if 'music' table exists in: {tables}")
    if 'music' not in tables:
        logger.info("Creating 'music' table")
        op.create_table('music',
            sa.Column('name', sa.String(length=100), nullable=False),
            sa.Column('description', sa.Text(), nullable=True),
            sa.Column('user_id', sa.Integer(), nullable=False),
            sa.Column('universe_id', sa.Integer(), nullable=False),
            sa.Column('scene_id', sa.Integer(), nullable=True),
            sa.Column('music_data', sa.JSON(), nullable=False),
            sa.Column('algorithm', sa.String(length=50), nullable=True),
            sa.Column('tempo', sa.Integer(), nullable=True),
            sa.Column('key', sa.String(length=10), nullable=True),
            sa.Column('scale', sa.String(length=20), nullable=True),
            sa.Column('parameters', sa.JSON(), nullable=True),
            sa.Column('audio_url', sa.String(length=255), nullable=True),
            sa.Column('id', sa.BigInteger(), nullable=False),
            sa.Column('created_at', sa.DateTime(), nullable=True),
            sa.Column('updated_at', sa.DateTime(), nullable=True),
            sa.Column('is_deleted', sa.Boolean(), nullable=True),
            sa.ForeignKeyConstraint(['scene_id'], ['scenes.id'], ondelete='CASCADE'),
            sa.ForeignKeyConstraint(['universe_id'], ['universes.id'], ondelete='CASCADE'),
            sa.ForeignKeyConstraint(['user_id'], ['users.id'], ondelete='CASCADE'),
            sa.PrimaryKeyConstraint('id')
        )
        with op.batch_alter_table('music', schema=None) as batch_op:
            batch_op.create_index(batch_op.f('ix_music_created_at'), ['created_at'], unique=False)
            batch_op.create_index(batch_op.f('ix_music_is_deleted'), ['is_deleted'], unique=False)
            batch_op.create_index(batch_op.f('ix_music_name'), ['name'], unique=False)
            batch_op.create_index(batch_op.f('ix_music_scene_id'), ['scene_id'], unique=False)
            batch_op.create_index(batch_op.f('ix_music_universe_id'), ['universe_id'], unique=False)
            batch_op.create_index(batch_op.f('ix_music_updated_at'), ['updated_at'], unique=False)
            batch_op.create_index(batch_op.f('ix_music_user_id'), ['user_id'], unique=False)
    else:
        logger.info("'music' table already exists, skipping creation")

    logger.info("Checking if 'physics_parameters' table exists")
    if 'physics_parameters' not in tables:
        logger.info("Creating 'physics_parameters' table")
        op.create_table('physics_parameters',
            sa.Column('name', sa.String(length=100), nullable=False),
            sa.Column('description', sa.Text(), nullable=True),
            sa.Column('user_id', sa.Integer(), nullable=False),
            sa.Column('universe_id', sa.Integer(), nullable=False),
            sa.Column('gravity_x', sa.Float(), nullable=False),
            sa.Column('gravity_y', sa.Float(), nullable=False),
            sa.Column('gravity_z', sa.Float(), nullable=False),
            sa.Column('fixed_timestep', sa.Float(), nullable=False),
            sa.Column('max_substeps', sa.Integer(), nullable=False),
            sa.Column('solver_iterations', sa.Integer(), nullable=False),
            sa.Column('collision_iterations', sa.Integer(), nullable=False),
            sa.Column('default_restitution', sa.Float(), nullable=False),
            sa.Column('default_friction', sa.Float(), nullable=False),
            sa.Column('default_linear_damping', sa.Float(), nullable=False),
            sa.Column('default_angular_damping', sa.Float(), nullable=False),
            sa.Column('continuous_collision_detection', sa.Boolean(), nullable=False),
            sa.Column('allow_sleep', sa.Boolean(), nullable=False),
            sa.Column('collision_margin', sa.Float(), nullable=False),
            sa.Column('air_density', sa.Float(), nullable=False),
            sa.Column('water_density', sa.Float(), nullable=False),
            sa.Column('use_aerodynamics', sa.Boolean(), nullable=False),
            sa.Column('id', sa.BigInteger(), nullable=False),
            sa.Column('created_at', sa.DateTime(), nullable=True),
            sa.Column('updated_at', sa.DateTime(), nullable=True),
            sa.Column('is_deleted', sa.Boolean(), nullable=True),
            sa.ForeignKeyConstraint(['universe_id'], ['universes.id'], ondelete='CASCADE'),
            sa.ForeignKeyConstraint(['user_id'], ['users.id'], ondelete='CASCADE'),
            sa.PrimaryKeyConstraint('id')
        )

        with op.batch_alter_table('physics_parameters', schema=None) as batch_op:
            batch_op.create_index(batch_op.f('ix_physics_parameters_created_at'), ['created_at'], unique=False)
            batch_op.create_index(batch_op.f('ix_physics_parameters_is_deleted'), ['is_deleted'], unique=False)
            batch_op.create_index(batch_op.f('ix_physics_parameters_name'), ['name'], unique=False)
            batch_op.create_index(batch_op.f('ix_physics_parameters_universe_id'), ['universe_id'], unique=False)
            batch_op.create_index(batch_op.f('ix_physics_parameters_updated_at'), ['updated_at'], unique=False)
            batch_op.create_index(batch_op.f('ix_physics_parameters_user_id'), ['user_id'], unique=False)
    else:
        logger.info("'physics_parameters' table already exists, skipping creation")

    logger.info("Checking if 'scene_notes' table exists")
    if 'scene_notes' not in tables:
        logger.info("Creating 'scene_notes' table")
        op.create_table('scene_notes',
            sa.Column('title', sa.String(length=100), nullable=False),
            sa.Column('content', sa.Text(), nullable=True),
            sa.Column('scene_id', sa.Integer(), nullable=False),
            sa.Column('type', sa.String(length=50), nullable=True),
            sa.Column('importance', sa.String(length=50), nullable=True),
            sa.Column('order', sa.Integer(), nullable=True),
            sa.Column('is_public', sa.Boolean(), nullable=False),
            sa.Column('id', sa.BigInteger(), nullable=False),
            sa.Column('created_at', sa.DateTime(), nullable=True),
            sa.Column('updated_at', sa.DateTime(), nullable=True),
            sa.Column('is_deleted', sa.Boolean(), nullable=True),
            sa.ForeignKeyConstraint(['scene_id'], ['scenes.id'], ondelete='CASCADE'),
            sa.PrimaryKeyConstraint('id')
        )

        with op.batch_alter_table('scene_notes', schema=None) as batch_op:
            batch_op.create_index(batch_op.f('ix_scene_notes_created_at'), ['created_at'], unique=False)
            batch_op.create_index(batch_op.f('ix_scene_notes_is_deleted'), ['is_deleted'], unique=False)
            batch_op.create_index(batch_op.f('ix_scene_notes_scene_id'), ['scene_id'], unique=False)
            batch_op.create_index(batch_op.f('ix_scene_notes_title'), ['title'], unique=False)
            batch_op.create_index(batch_op.f('ix_scene_notes_updated_at'), ['updated_at'], unique=False)
    else:
        logger.info("'scene_notes' table already exists, skipping creation")

    # Continue with the rest of the migration (altering tables)
    logger.info("Proceeding with column modifications for existing tables")

    with op.batch_alter_table('audio_samples', schema=None) as batch_op:
        batch_op.alter_column('id',
               existing_type=sa.INTEGER(),
               type_=sa.BigInteger(),
               existing_nullable=False,
               autoincrement=True)

    with op.batch_alter_table('characters', schema=None) as batch_op:
        batch_op.alter_column('id',
            existing_type=sa.INTEGER(),
            type_=sa.BigInteger(),
            existing_nullable=False,
            autoincrement=True,
            existing_server_default="nextval('characters_id_seq'::regclass)")

    with op.batch_alter_table('harmonies', schema=None) as batch_op:
        batch_op.alter_column('id',
            existing_type=sa.INTEGER(),
            type_=sa.BigInteger(),
            existing_nullable=False,
            autoincrement=True)

    with op.batch_alter_table('music_pieces', schema=None) as batch_op:
        batch_op.alter_column('id',
            existing_type=sa.INTEGER(),
            type_=sa.BigInteger(),
            existing_nullable=False,
            autoincrement=True)

    with op.batch_alter_table('musical_themes', schema=None) as batch_op:
        batch_op.alter_column('id',
            existing_type=sa.INTEGER(),
            type_=sa.BigInteger(),
            existing_nullable=False,
            autoincrement=True)

    with op.batch_alter_table('notes', schema=None) as batch_op:
        batch_op.alter_column('id',
            existing_type=sa.INTEGER(),
            type_=sa.BigInteger(),
            existing_nullable=False,
            autoincrement=True)

    with op.batch_alter_table('physics_2d', schema=None) as batch_op:
        batch_op.alter_column('id',
            existing_type=sa.INTEGER(),
            type_=sa.BigInteger(),
            existing_nullable=False,
            autoincrement=True)

    with op.batch_alter_table('physics_3d', schema=None) as batch_op:
        batch_op.alter_column('id',
            existing_type=sa.INTEGER(),
            type_=sa.BigInteger(),
            existing_nullable=False,
            autoincrement=True)

    with op.batch_alter_table('physics_constraints', schema=None) as batch_op:
        batch_op.alter_column('id',
            existing_type=sa.INTEGER(),
            type_=sa.BigInteger(),
            existing_nullable=False,
            autoincrement=True)

    with op.batch_alter_table('physics_objects', schema=None) as batch_op:
        batch_op.alter_column('id',
            existing_type=sa.INTEGER(),
            type_=sa.BigInteger(),
            existing_nullable=False,
            autoincrement=True)

    with op.batch_alter_table('scenes', schema=None) as batch_op:
        batch_op.alter_column('id',
            existing_type=sa.INTEGER(),
            type_=sa.BigInteger(),
            existing_nullable=False,
            autoincrement=True,
            existing_server_default="nextval('scenes_id_seq'::regclass)")

    with op.batch_alter_table('sound_profiles', schema=None) as batch_op:
        batch_op.alter_column('ambient_volume',
            existing_type=sa.DOUBLE_PRECISION(precision=53),
            nullable=False)
        batch_op.alter_column('music_volume',
            existing_type=sa.DOUBLE_PRECISION(precision=53),
            nullable=False)
        batch_op.alter_column('effects_volume',
            existing_type=sa.DOUBLE_PRECISION(precision=53),
            nullable=False)
        batch_op.alter_column('id',
            existing_type=sa.INTEGER(),
            type_=sa.BigInteger(),
            existing_nullable=False,
            autoincrement=True,
            existing_server_default="nextval('sound_profiles_id_seq'::regclass)")

    with op.batch_alter_table('universes', schema=None) as batch_op:
        batch_op.add_column(sa.Column('genre', sa.String(length=100), nullable=True))
        batch_op.add_column(sa.Column('theme', sa.String(length=100), nullable=True))
        batch_op.alter_column('id',
            existing_type=sa.INTEGER(),
            type_=sa.BigInteger(),
            existing_nullable=False,
            autoincrement=True,
            existing_server_default="nextval('universes_id_seq'::regclass)")

    with op.batch_alter_table('users', schema=None) as batch_op:
        batch_op.alter_column('id',
            existing_type=sa.INTEGER(),
            type_=sa.BigInteger(),
            existing_nullable=False,
            autoincrement=True,
            existing_server_default="nextval('users_id_seq'::regclass)")

    # ### end Alembic commands ###

def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('users', schema=None) as batch_op:
        batch_op.alter_column('id',
            existing_type=sa.BigInteger(),
            type_=sa.INTEGER(),
            existing_nullable=False,
            autoincrement=True,
            existing_server_default="nextval('users_id_seq'::regclass)")

    with op.batch_alter_table('universes', schema=None) as batch_op:
        batch_op.alter_column('id',
            existing_type=sa.BigInteger(),
            type_=sa.INTEGER(),
            existing_nullable=False,
            autoincrement=True,
            existing_server_default="nextval('universes_id_seq'::regclass)")
        batch_op.drop_column('theme')
        batch_op.drop_column('genre')

    with op.batch_alter_table('sound_profiles', schema=None) as batch_op:
        batch_op.alter_column('id',
            existing_type=sa.BigInteger(),
            type_=sa.INTEGER(),
            existing_nullable=False,
            autoincrement=True,
            existing_server_default="nextval('sound_profiles_id_seq'::regclass)")
        batch_op.alter_column('effects_volume',
            existing_type=sa.DOUBLE_PRECISION(precision=53),
            nullable=True)
        batch_op.alter_column('music_volume',
            existing_type=sa.DOUBLE_PRECISION(precision=53),
            nullable=True)
        batch_op.alter_column('ambient_volume',
            existing_type=sa.DOUBLE_PRECISION(precision=53),
            nullable=True)

    with op.batch_alter_table('scenes', schema=None) as batch_op:
        batch_op.alter_column('id',
            existing_type=sa.BigInteger(),
            type_=sa.INTEGER(),
            existing_nullable=False,
            autoincrement=True,
            existing_server_default="nextval('scenes_id_seq'::regclass)")

    with op.batch_alter_table('physics_objects', schema=None) as batch_op:
        batch_op.alter_column('id',
            existing_type=sa.BigInteger(),
            type_=sa.INTEGER(),
            existing_nullable=False,
            autoincrement=True)

    with op.batch_alter_table('physics_constraints', schema=None) as batch_op:
        batch_op.alter_column('id',
            existing_type=sa.BigInteger(),
            type_=sa.INTEGER(),
            existing_nullable=False,
            autoincrement=True)

    with op.batch_alter_table('physics_3d', schema=None) as batch_op:
        batch_op.alter_column('id',
            existing_type=sa.BigInteger(),
            type_=sa.INTEGER(),
            existing_nullable=False,
            autoincrement=True)

    with op.batch_alter_table('physics_2d', schema=None) as batch_op:
        batch_op.alter_column('id',
            existing_type=sa.BigInteger(),
            type_=sa.INTEGER(),
            existing_nullable=False,
            autoincrement=True)

    with op.batch_alter_table('notes', schema=None) as batch_op:
        batch_op.alter_column('id',
            existing_type=sa.BigInteger(),
            type_=sa.INTEGER(),
            existing_nullable=False,
            autoincrement=True)

    with op.batch_alter_table('musical_themes', schema=None) as batch_op:
        batch_op.alter_column('id',
            existing_type=sa.BigInteger(),
            type_=sa.INTEGER(),
            existing_nullable=False,
            autoincrement=True)

    with op.batch_alter_table('music_pieces', schema=None) as batch_op:
        batch_op.alter_column('id',
            existing_type=sa.BigInteger(),
            type_=sa.INTEGER(),
            existing_nullable=False,
            autoincrement=True)

    with op.batch_alter_table('harmonies', schema=None) as batch_op:
        batch_op.alter_column('id',
            existing_type=sa.BigInteger(),
            type_=sa.INTEGER(),
            existing_nullable=False,
            autoincrement=True)

    with op.batch_alter_table('characters', schema=None) as batch_op:
        batch_op.alter_column('id',
            existing_type=sa.BigInteger(),
            type_=sa.INTEGER(),
            existing_nullable=False,
            autoincrement=True,
            existing_server_default="nextval('characters_id_seq'::regclass)")

    with op.batch_alter_table('audio_samples', schema=None) as batch_op:
        batch_op.alter_column('id',
            existing_type=sa.BigInteger(),
            type_=sa.INTEGER(),
            existing_nullable=False,
            autoincrement=True)

    with op.batch_alter_table('scene_notes', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_scene_notes_updated_at'))
        batch_op.drop_index(batch_op.f('ix_scene_notes_title'))
        batch_op.drop_index(batch_op.f('ix_scene_notes_scene_id'))
        batch_op.drop_index(batch_op.f('ix_scene_notes_is_deleted'))
        batch_op.drop_index(batch_op.f('ix_scene_notes_created_at'))

    op.drop_table('scene_notes')
    with op.batch_alter_table('physics_parameters', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_physics_parameters_user_id'))
        batch_op.drop_index(batch_op.f('ix_physics_parameters_updated_at'))
        batch_op.drop_index(batch_op.f('ix_physics_parameters_universe_id'))
        batch_op.drop_index(batch_op.f('ix_physics_parameters_name'))
        batch_op.drop_index(batch_op.f('ix_physics_parameters_is_deleted'))
        batch_op.drop_index(batch_op.f('ix_physics_parameters_created_at'))

    op.drop_table('physics_parameters')
    with op.batch_alter_table('music', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_music_user_id'))
        batch_op.drop_index(batch_op.f('ix_music_updated_at'))
        batch_op.drop_index(batch_op.f('ix_music_universe_id'))
        batch_op.drop_index(batch_op.f('ix_music_scene_id'))
        batch_op.drop_index(batch_op.f('ix_music_name'))
        batch_op.drop_index(batch_op.f('ix_music_is_deleted'))
        batch_op.drop_index(batch_op.f('ix_music_created_at'))

    op.drop_table('music')
    # ### end Alembic commands ###
